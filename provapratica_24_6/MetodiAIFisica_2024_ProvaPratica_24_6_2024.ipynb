{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcp8O5nmtTJu0VzZ5KBkTf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefanogiagu/corso_AI_2024/blob/main/provapratica_24_6/MetodiAIFisica_2024_ProvaPratica_24_6_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova Pratica - Metodi AI per la fisica\n",
        "### 24.6.2024 - AA 2023/24 - Docente: S. Giagu\n",
        "\n",
        "\n",
        "> **Regole:**\n",
        "\n",
        "*   **tempo a disposizione:** 2.5h\n",
        "\n",
        "*   compilare con i vostri dati i campi della cella che segue e poi eseguire la cella verificando che i dati printati corrispondano. L'esecuzione della cella scarica anche i dataset da utilizzare durante la prova;\n",
        "*   risolvere i quesiti/compiti indicati nella cella *Descrizione del compito*. È richiesto di risolvere un problema a scelta tra i problema *A1* e *A2*, e un problema a scelta tra i problemi *B1* e *B2*;\n",
        "*   una volta completato il compito caricare il notebook nel apposito folder sul sito e-learning del corso disponibile al link: <p>\n",
        "[consegna esonero](https://elearning.uniroma1.it/mod/assign/view.php?id=647726)<p>\n",
        "\n",
        "**NOTA 1:** per scaricare localmente il notebook da colab: menù **File->Dowload->Download .ipynb** (non è necessario cambiare il nome del file, il form e-learning associa automaticamnte un folder con il vostro nome e id al file che caricate)\n",
        "<p>\n",
        "\n",
        "**NOTA 2:** una volta caricato e sottomesso il notebook non sono più possibili ulteriori modifiche."
      ],
      "metadata": {
        "id": "bc9160FmJpVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Dati Personali\n",
        "import os\n",
        "\n",
        "Nome = 'Stefano'  #@param {type: \"string\"}\n",
        "Cognome = 'Giagu' #@param {type: \"string\"}\n",
        "NumeroMatricola = 12345678 #@param {type: \"number\"}\n",
        "\n",
        "if NumeroMatricola == 12345678:\n",
        "  print('\\033[1;31m Inserisci il numero di matricola corretto!!!!')\n",
        "else:\n",
        "  print('Download datasets ...')\n",
        "  !wget !wget http://giagu.web.cern.ch/giagu/CERN/dataset_1_AI_24.6.2024.npz\n",
        "  !wget !wget http://giagu.web.cern.ch/giagu/CERN/dataset_2_AI_24.6.2024.npy\n",
        "  !ls\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "DNPSWZsGV0hy",
        "outputId": "a596ad77-363a-490c-f419-19389bb9d6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31m Inserisci il numero di matricola corretto!!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrizione del compito:\n",
        "\n",
        "Svolgere uno tra i due problemi A1 e A2, e uno tra i due problemi B1 e B2.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Problema A1**\n",
        "\n",
        "Viene fornito il dataset in formato numpy compresso: *dataset_1_AI_24.6.2024.npz*, contenente 10000 esempi di eventi descritti da vettori di 30 feature ciascuno (vettore $X$ di shape $(10000,30)$.\n",
        "\n",
        "Per leggere il dataset utilizzare l'esempio di codice:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "f1 = np.load('dataset_1_AI_24.6.2024.npz')\n",
        "X = f1['X']\n",
        "```\n",
        "\n",
        "1. (A1.1): usare l'algoritmo *k-means* per clusterizzare il dataset;\n",
        "2. (A1.2): stimare il numero di cluster utilizzando una tecnica opportuna;\n",
        "3. (A1.3): graficare i risultati ottenuti in un plot bidimensionale colorando ciascun punto in accordo all'indice di cluster fornito da *k-means*;\n",
        "4. (A1.4): applicare un algoritmo di clustering basato su GMM, con numero di cluster ottenuto dal punto A1.2, e stimare la distanza che gli eventi definiti dai feature vectors *A* e *B* hanno dal cluster del GMM che gli è più vicino:\n",
        "\n",
        "\n",
        "> ```\n",
        "A =  np.array([[-5.36505473,  2.07195568,  4.91825063, -4.11366628, -1.42774354,\n",
        "         0.1108879 ,  1.12768349, -3.71341838,  6.30737198,  1.84406497,\n",
        "         3.69745021,  0.66683686,  2.51573212, -3.06422791, -3.05325371,\n",
        "        -3.17967819, -1.0235818 , -0.05819968,  1.52060631, -1.48816709,\n",
        "         1.58701788, -2.89491225,  1.3980812 ,  4.35015951,  0.11112597,\n",
        "        -2.88989763, -1.42208498, -2.21855776,  3.03341608,  3.81970948]])\n",
        "> B = np.array([[-2.64458179,  1.95884469,  2.99352898, -0.2119196 , -0.60619392,\n",
        "         1.98684426, -1.48225564, -4.36632599,  3.68098531, -0.0859702 ,\n",
        "         1.45377991, -1.98137052,  4.02635899, -1.00188601, -1.55315421,\n",
        "        -3.26681447, -3.9642281 ,  1.47756927,  2.24695055, -3.54575546,\n",
        "        -0.51456593, -1.78531078,  0.02494651,  0.68843177, -2.84264001,\n",
        "         0.63410389, -3.38430242, -2.16836076,  0.78456835,  3.83921132]])\n",
        "```\n",
        "\n",
        "\n",
        "5. (A1.5): graficare il plot del punto A1.3 colorando i punti con l'indice di cluster fornito dal modello GMM, graficando nello stesso plot i punti corrispondenti agli eventi A e B.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "---\n",
        "\n",
        "**Problema A2**\n",
        "\n",
        "Viene fornito il dataset in formato numpy: *dataset_2_AI_24.6.2024.npy*, contenente 400 immagini in scala di grigio di dimensione $(64,64)$ pixels.\n",
        "\n",
        "Per leggere il dataset utilizzare il codice:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "data=np.load('dataset_2_AI_24.6.2024.npy')\n",
        "```\n",
        "\n",
        "1. (A2.1): applicare una riduzione dimensionale 2D basata su PCA e calcolare la varianza spiegata delle due componenti\n",
        "2. (A2.2): graficare lo spazio latente PCA 2D del dataset\n",
        "3. (A2.3): allenare un autoencoder basato su una rete feed-forward shallow (un solo layer nascosto per l'encoder e uno solo per il decoder) con layer lineari, senza parametri di bias e con attivazioni lineari, con rappresentazione latente di dimensione 2, usando MSE come funzione di costo;\n",
        "4. (A2.4): graficare lo spazio latente 2D e confrontare con quanto ottenuto al punto A2.2, commentando il risultato ottenuto.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "---\n",
        "\n",
        "**Problema B1**\n",
        "\n",
        "5. (B1.1): leggere il dataset MNIST da *openml *e graficare 3 immagini scelte in modo random dal campione;\n",
        "6. (B1.2): allenare un modello CNN rispetto al task di classificazione del campione MNIST;\n",
        "7. (B1.3): graficare le *traiettorie di apprendimento della rete*:\n",
        "-  ad ogni epoca di training salvare in un opportuno vettore numpy il valore di tutti i pesi dell'ultimo layer convoluzionale della CNN:\n",
        "\n",
        "```\n",
        "# Suggerimento per accedere al valore dei pesi di un dato layer convoluzionale di un modello DNN \"model\":\n",
        "# se nel modello il layer convoluzionale di interesse è stato per esempio definito dalla istanza:\n",
        "self.conv3 = nn.Conv2d(...)\n",
        "# allora è possibile ottenere il valore corrente dei pesi associati a quel layer tramite l'istruzione:\n",
        "model.conv3.weight.flatten().detach().numpy()\n",
        "```\n",
        "\n",
        "> NOTA: bisogna scrivere il codice in modo da ottenere alla fine dell'allenamento un vettore numpy di dimensione *(numero epoche, numero parametri dell'ultimo layer convoluzionale)*\n",
        "\n",
        "- terminato l'addestramento applicare una PCA 2D al vettore dei pesi per ogni epoca, e graficare lo scatter plot di *pca_0 vs pca_1*, colorando ciascun punto in accordo all'indice di epoca.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto.\n",
        "\n",
        "---\n",
        "\n",
        "**Problema B2**\n",
        "\n",
        "Viene fornito un dataset costituito da 500 coppie di punti $(x_{obs}, y_{obs})$, estratti in accordo ad una relazione funzionale 1D: $y=f(x)$ + noise:\n",
        "\n",
        "\n",
        "```\n",
        "# Funzione 1D fornita\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate data\n",
        "x_obs = np.hstack([np.linspace(-0.2, 0.2, 500), np.linspace(0.6, 1, 500)])\n",
        "noise = 0.02 * np.random.randn(x_obs.shape[0])\n",
        "y_obs = x_obs + 0.3 * np.sin(2 * np.pi * (x_obs + noise)) + 0.3 * np.sin(4 * np.pi * (x_obs + noise)) + noise\n",
        "\n",
        "# Set plot limits and labels\n",
        "xlims = [-0.5, 1.5]\n",
        "ylims = [-1.5, 2.5]\n",
        "\n",
        "# True values\n",
        "x_true = np.linspace(-0.5, 1.5, 1000)\n",
        "y_true = x_true + 0.3 * np.sin(2 * np.pi * x_true) + 0.3 * np.sin(4 * np.pi * x_true)\n",
        "\n",
        "# test set\n",
        "x_test = torch.linspace(xlims[0], xlims[1], 3000)\n",
        "\n",
        "# Create plot\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.plot(x_true, y_true, 'b-', linewidth=3, label=\"True function\")\n",
        "ax.plot(x_obs, y_obs, 'ko', markersize=4, label=\"Observations\")\n",
        "ax.set_xlim(xlims)\n",
        "ax.set_ylim(ylims)\n",
        "ax.set_xlabel(\"X\", fontsize=30)\n",
        "ax.set_ylabel(\"Y\", fontsize=30)\n",
        "ax.legend(loc=4, fontsize=15, frameon=False)\n",
        "\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "5. (B2.1): implementare una architettura MLP per il task di regressione: *predire y_obs dato x_obs*;\n",
        "6. (B2.2): allenare 5 modelli della stessa architettura B2.1, utilizzando lo  stesso dataset, ma con inizalizzazione random dei pesi di ogni modello;\n",
        "7. (B2.3): sullo stesso plot graficare i valori \"true\" della funzione $y=f(x)$,\n",
        "i punti del dataset di training $(x_{obs}, y_{obs})$, e il valore medio della predizione di $y$ ottenuto dalle 5 versioni del modello allenate nel punto B2.2, insieme alla banda di incertezza a $\\pm 3\\sigma$ intorno a tale predizione media.\n",
        "\n",
        "* commentare opportunamente i risultati ottenuti in ogni punto."
      ],
      "metadata": {
        "id": "IjeivMlvZdhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#... codice ..."
      ],
      "metadata": {
        "id": "Gog0PCCgoTWO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}